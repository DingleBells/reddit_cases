{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb1232c08c519f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T21:49:59.663133Z",
     "start_time": "2025-07-16T21:49:59.659657Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from google import genai\n",
    "import praw\n",
    "import prawcore\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from geopy.distance import geodesic\n",
    "from praw.models import MoreComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ab5c2f61c47f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T21:50:41.973603Z",
     "start_time": "2025-07-16T21:50:41.967095Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_comments_string(comments, level=0, printed=None, max_comments=10):\n",
    "\t# Get the comments from a post and return a string of the comments\n",
    "\tif printed is None:\n",
    "\t\tprinted = [0]\n",
    "\tresult = []\n",
    "\tindent = \"    \" * level\n",
    "\tfor comment in comments:\n",
    "\t\tif printed[0] >= max_comments:\n",
    "\t\t\tbreak\n",
    "\t\tif isinstance(comment, MoreComments):\n",
    "\t\t\tcontinue\n",
    "\t\tline = f\"{indent}- {comment.body}\"\n",
    "\t\tresult.append(line)\n",
    "\t\tprinted[0] += 1\n",
    "\t\tif comment.replies:\n",
    "\t\t\tresult.append(\n",
    "\t\t\t\tget_comments_string(comment.replies, level + 1, printed, max_comments)\n",
    "\t\t\t)\n",
    "\treturn \"\\n\".join(result)\n",
    "\n",
    "def extract_index_list(text):\n",
    "    # Look for Python-style list inside optional code block markers\n",
    "\t# Used for extracting the list of indices from the LLM output\n",
    "    match = re.search(r'\\[.*?\\]', text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return ast.literal_eval(match.group())\n",
    "        except Exception as e:\n",
    "            print(\"Failed to evaluate list:\", e)\n",
    "    return []\n",
    "\n",
    "def create_subreddits_df(subreddit_list, reddit, limit_=10):\n",
    "\t# Create a DataFrame of posts from the subreddits\n",
    "\t# This is the first step in the pipeline, where we get all the posts from the subreddits\n",
    "\tposts = []\n",
    "\tfor sub in subreddit_list:\n",
    "\t\ttry:\n",
    "\t\t\tsub = reddit.subreddit(sub)\n",
    "\t\t\tfor post in sub.hot(limit=limit_):\n",
    "\t\t\t\tposts.append({\n",
    "\t\t\t\t\t'subreddit': sub,\n",
    "\t\t\t\t\t'title': post.title,\n",
    "\t\t\t\t\t'body': post.selftext,\n",
    "\t\t\t\t\t'num_comments': post.num_comments,\n",
    "\t\t\t\t\t'comments': get_comments_string(post.comments.list())\n",
    "\t\t\t\t})\n",
    "\t\texcept prawcore.exceptions.NotFound:\n",
    "\t\t\tprint(f\"Subreddit not found: {sub}\")\n",
    "\t\texcept prawcore.exceptions.Forbidden:\n",
    "\t\t\tprint(f\"Access forbidden: {sub}\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Other error with {sub}: {e}\")\n",
    "\treturn pd.DataFrame(posts)\n",
    "\n",
    "\n",
    "def filter_complaints_df(df, client):\n",
    "\t# Look at just the title and first 100 characters of the body paragraph to screen out irrelevant posts\n",
    "\t# This is the second step in the pipeline, where we use the LLM to screen out irrelevant posts\n",
    "\toutdf = []\n",
    "\tresult = client.models.generate_content(\n",
    "\t\tmodel='gemini-2.5-flash-lite-preview-06-17',\n",
    "\t\tcontents=f\"\"\"Based on this list of post titles from local subreddits, determine if each post might contain information that has the potential for class action litigation based on public nuisance and loss of use/enjoyment. Keep track of only the index (0-indexed) of each relevant title. For example, output 0 if the first post is titled 'Excessive odors coming from local power plant' and nothing for a post titled 'Local barbers in area?' If the title is ambiguous, assume that it is relevant. Output a only list of all the relevant indices, with no other text. Here is the list of titles: {df['title'].tolist()}\"\"\"\n",
    "\t)\n",
    "\tindices = extract_index_list(result.text)\n",
    "\tfor i in indices:\n",
    "\t\tif 0 <= i < len(df):\n",
    "\t\t\toutdf.append(df.iloc[i])\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"Warning: Index {i} is out of bounds for DataFrame of length {len(df)}\")\n",
    "\n",
    "\treturn pd.DataFrame(outdf)\n",
    "\n",
    "\n",
    "def find_litigation_areas(df, client):\n",
    "\t# Use LLM to find litigation areas given the DataFrame of relevant posts\n",
    "\t# Save DataFrame to CSV\n",
    "\t# This is the third step in the pipeline, where we use the LLM to find litigation areas\n",
    "\tdf.to_csv(\"litigation.csv\", index=False)\n",
    "\n",
    "\t# Upload file using its path\n",
    "\tmydf = client.files.upload(file=\"litigation.csv\")\n",
    "\n",
    "\t# Generate content using uploaded file\n",
    "\tresult = client.models.generate_content(\n",
    "\t\tmodel='gemini-2.5-flash-lite-preview-06-17',\n",
    "\t\tcontents=[\n",
    "\t\t\tmydf,\n",
    "\t\t\t'''Based on the following table of Reddit posts from this area, identify communities experiencing sustained environmental complaints over the past 3â€“6 months.\n",
    "\n",
    "Focus on issues relevant to public nuisance or loss of use/enjoyment, and summarize results briefly to conserve output tokens.\n",
    "\n",
    "For each issue or cluster, include:\n",
    "\n",
    "Community name or general area (e.g., \"Downtown Palo Alto\")\n",
    "\n",
    "Type of issue (e.g., odor, noise, air pollution)\n",
    "\n",
    "Estimated residents affected (e.g., 100+, 1000+)\n",
    "\n",
    "Responsible party, if known\n",
    "\n",
    "Mitigation mentioned? (Yes/No)\n",
    "\n",
    "Return the results in a compact, bulleted pointed format. Do not provide explanations or narrative.\n",
    "Please include as many relevant entries as possible, up to 10.'''\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\treturn result.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154384c2d00e3348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T21:27:29.576377Z",
     "start_time": "2025-07-16T21:27:29.573667Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_subreddits_by_distance(center_lat, center_lon, radius_miles):\n",
    "\t# Given a set of coordinates, filter the subreddits to only those within a certain radius\n",
    "\tdf = pd.read_csv('files/reddit_data.csv')\n",
    "\torigin = (center_lat, center_lon)\n",
    "\n",
    "\t# Compute distance for each row\n",
    "\tdef is_within_radius(row):\n",
    "\t\tlocation = (row['Latitude'], row['Longitude'])\n",
    "\t\treturn geodesic(origin, location).miles <= radius_miles\n",
    "\n",
    "\tfiltered_df = df[df.apply(is_within_radius, axis=1)].reset_index(drop=True)\n",
    "\treturn filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e466b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def keyword_filter(df, keywords, log_file=\"keyword_filter_log.txt\"):\n",
    "    # Filters DataFrame rows where any keyword appears in title or body.\n",
    "    # Logs matches and keyword hit counts.\n",
    "    # Returns filtered DataFrame and a dict of keyword hit counts.\n",
    "    \n",
    "    hit_counts = {kw: 0 for kw in keywords}\n",
    "    matches = []\n",
    "\n",
    "    with open(log_file, \"w\") as log:\n",
    "        for idx, row in df.iterrows():\n",
    "            title = str(row['title']).lower()\n",
    "            body = str(row['body']).lower()\n",
    "            matched_keywords = [kw for kw in keywords if kw in title or kw in body]\n",
    "            if matched_keywords:\n",
    "                matches.append(idx)\n",
    "                for kw in matched_keywords:\n",
    "                    hit_counts[kw] += 1\n",
    "                log.write(f\"Row {idx}: Matched keywords {matched_keywords} in title/body: \\\"{row['title']}\\\"\\n\")\n",
    "        log.write(\"\\nKeyword hit counts:\\n\")\n",
    "        for kw, count in hit_counts.items():\n",
    "            log.write(f\"{kw}: {count}\\n\")\n",
    "\n",
    "    filtered_df = df.loc[matches].reset_index(drop=True)\n",
    "    return filtered_df, hit_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1911b5ed4c246bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T21:54:51.950355Z",
     "start_time": "2025-07-16T21:54:51.946596Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(center_lat, center_lon, radius_miles, lim=10):\n",
    "\t# This is the main function that will be called to run all the functions in order\n",
    "\t# First create the reddit and genai using the keys from the .env file\n",
    "\tload_dotenv()\n",
    "\treddit = praw.Reddit(\n",
    "\t\tclient_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "\t\tclient_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "\t\tuser_agent=os.getenv('REDDIT_USER_AGENT')\n",
    "\t)\n",
    "\n",
    "\tclient = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "\t# Next, filter the list of subreddits by location\n",
    "\tprint(\"Filtering subreddits by location...\")\n",
    "\tsub_list = filter_subreddits_by_distance(center_lat, center_lon, radius_miles)['Subreddit'].tolist()\n",
    "\tprint(\"Done.\")\n",
    "\n",
    "\t# Grab all the recent posts from those subreddits and condense into dataframe\n",
    "\tprint(\"Fetching posts from subreddits...\")\n",
    "\tsub_df = create_subreddits_df(sub_list, reddit, lim)\n",
    "\tprint(\"Done.\")\n",
    "\n",
    "\t# Keyword filter before LLM filtering\n",
    "\tKEYWORDS = [\n",
    "    \"odor\", \"smell\", \"noise\", \"loud\", \"pollution\", \"toxic\", \"contamination\",\n",
    "    \"smoke\", \"dust\", \"vibration\", \"hazard\", \"waste\", \"dump\", \"spill\",\n",
    "    \"illegal\", \"danger\", \"health\", \"asthma\", \"allergy\", \"air quality\",\n",
    "    \"water quality\", \"sewage\", \"garbage\", \"trash\", \"rats\", \"vermin\",\n",
    "    \"mold\", \"leak\", \"chemical\", \"factory\", \"plant\", \"refinery\", \"power plant\"\n",
    "\t]\n",
    "\tprint(\"Applying keyword filter...\")\n",
    "\tkeyword_filtered_df, keyword_hits = keyword_filter(sub_df, KEYWORDS)\n",
    "\tprint(f\"Keyword filter found {len(keyword_filtered_df)} posts. See 'keyword_filter_log.txt' for details.\")\n",
    "\tprint(\"Top keyword hits:\", {k: v for k, v in keyword_hits.items() if v > 0})\n",
    "\n",
    "\t# Now filter the posts by title to grab only potentially relevant posts\n",
    "\tprint(\"Filtering posts...\")\n",
    "\tsub_df2 = filter_complaints_df(sub_df, client)\n",
    "\tprint(\"Done.\")\n",
    "\n",
    "\tprint(\"Analyzing posts...\")\n",
    "\t# Now analyze the filtered posts and return summary of the complaints\n",
    "\tfinal = find_litigation_areas(sub_df, client)\n",
    "\treturn sub_df, sub_df2, final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b85873b79c62e96e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T22:05:05.014812Z",
     "start_time": "2025-07-16T22:04:00.526954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering subreddits by location...\n",
      "Done.\n",
      "Fetching posts from subreddits...\n",
      "Subreddit not found: losaltoshills\n",
      "Done.\n",
      "Applying keyword filter...\n",
      "Keyword filter found 7 posts. See 'keyword_filter_log.txt' for details.\n",
      "Top keyword hits: {'smell': 1, 'noise': 1, 'loud': 1, 'dust': 1, 'dump': 1, 'danger': 1, 'health': 2}\n",
      "Filtering posts...\n",
      "Done.\n",
      "Analyzing posts...\n",
      "* **NewarkCA**\n",
      "    * **Type of issue:** Noise (trains)\n",
      "    * **Estimated residents affected:** 1000+\n",
      "    * **Responsible party:** Unknown (railroad company)\n",
      "    * **Mitigation mentioned:** Yes (Quiet Zone project, soundproofing, earplugs)\n",
      "* **SanCarlos**\n",
      "    * **Type of issue:** Noise (trains)\n",
      "    * **Estimated residents affected:** 1000+\n",
      "    * **Responsible party:** Unknown (railroad company)\n",
      "    * **Mitigation mentioned:** Yes (earplugs, soundproofing)\n",
      "* **RedwoodCity**\n",
      "    * **Type of issue:** Noise (trains)\n",
      "    * **Estimated residents affected:** 1000+\n",
      "    * **Responsible party:** Unknown (railroad company)\n",
      "    * **Mitigation mentioned:** Yes (pickup soccer games at Red Morton park, afternoon practices)\n"
     ]
    }
   ],
   "source": [
    "# Palo Alto, radius 10\n",
    "all2, filtered2, final2 = main(37.4419, -122.1430, radius_miles=10)\n",
    "print(final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828a52496725339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T21:56:41.858566Z",
     "start_time": "2025-07-16T21:55:29.330256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering subreddits by location...\n",
      "Done.\n",
      "Fetching posts from subreddits...\n",
      "Access forbidden: Batavia\n",
      "Subreddit not found: elmwoodpark\n",
      "Subreddit not found: MichiganCityIndiana\n",
      "Access forbidden: NorthwestIndiana\n",
      "Access forbidden: McHenry\n",
      "Subreddit not found: CrownPointIndiana\n",
      "Access forbidden: barringtonil\n",
      "Access forbidden: PortagePark\n",
      "Other error with roundlake: received 429 HTTP response\n",
      "Other error with StCharlesIL: received 429 HTTP response\n",
      "Other error with elgin: received 429 HTTP response\n",
      "Other error with grayslake: received 429 HTTP response\n",
      "Other error with auroraillinois: received 429 HTTP response\n",
      "Other error with michiana: received 429 HTTP response\n",
      "Other error with oakparkil: received 429 HTTP response\n",
      "Other error with BartlettIllinois: received 429 HTTP response\n",
      "Done.\n",
      "Applying keyword filter...\n",
      "Keyword filter found 29 posts. See 'keyword_filter_log.txt' for details.\n",
      "Top keyword hits: {'smell': 1, 'noise': 2, 'loud': 4, 'pollution': 1, 'smoke': 1, 'dust': 4, 'waste': 2, 'spill': 1, 'illegal': 2, 'health': 6, 'garbage': 2, 'rats': 1, 'leak': 1, 'plant': 3}\n",
      "Filtering posts...\n",
      "Done.\n",
      "Analyzing posts...\n",
      "- **Elgin, Illinois:** Streetlight pollution (excessively bright LEDs), impacting wildlife and trees. Estimated residents affected: Unknown, but potentially widespread within Elgin. Responsible party: City of Elgin. Mitigation mentioned: Yes (dimming lights, keeping lights off outside).\n",
      "- **Elmhurst, Illinois:** Rabbit nuisance (destroying plants, digging under fences). Estimated residents affected: Unknown, but impacting multiple residents with yards. Responsible party: Rabbits (natural nuisance). Mitigation mentioned: Yes (sprays, chicken wire fencing, live traps, filling nests, dogs, foxes).\n",
      "- **Chicago:** Air quality issues (wildfire smoke). Estimated residents affected: Unknown, but significant throughout the city. Responsible party: Wildfires (external). Mitigation mentioned: No (beyond general awareness).\n",
      "- **Chicago:** Noise pollution (loud guy with dogs in Clifton). Estimated residents affected: Unknown, but specifically targeting a resident in Clifton. Responsible party: Unidentified loud individual. Mitigation mentioned: No.\n",
      "- **Downers Grove, Illinois:** Road construction (unspecified, but causing traffic issues). Estimated residents affected: Unknown, but impacting those using local roads. Responsible party: Unknown (likely municipality or contractor). Mitigation mentioned: No.\n",
      "- **Waukegan, Illinois:** DMV issues (difficulty obtaining loan agreement copy). Estimated residents affected: Unknown, but impacting a specific resident. Responsible party: DMV/Financial Institution. Mitigation mentioned: No (seeking advice).\n",
      "- **Berwyn, Illinois:** Block party nuisance (excessive noise, crowds, out-of-control behavior, unaddressed blight). Estimated residents affected: Unknown, but impacting residents near block parties. Responsible party: Block party participants, City of Berwyn (lack of enforcement). Mitigation mentioned: No (complaints made, but no action).\n",
      "- **Arlington Heights, Illinois:** Road upkeep and lack of bike lanes (main roads in poor condition, dangerous for cyclists). Estimated residents affected: Unknown, but impacting cyclists and potentially drivers due to road condition. Responsible party: City of Arlington Heights. Mitigation mentioned: Yes (bike routes exist, but are insufficient).\n",
      "- **Carol Stream, Illinois:** Stagnant village government (lack of family-friendly establishments, lack of progress). Estimated residents affected: Unknown, but impacting the community's development. Responsible party: Village government. Mitigation mentioned: No (seeking information on candidates).\n",
      "- **Kenosha, Wisconsin:** Harrassing door-to-door pest control sales people (persistent, unwilling to take no for an answer). Estimated residents affected: Unknown, but a recurring issue for some residents. Responsible party: Pest control sales companies. Mitigation mentioned: Yes (telling them to place on do-not-return list, not answering door).\n"
     ]
    }
   ],
   "source": [
    "# Chicago, radius 50\n",
    "all, filtered, final = main(41.887442, -87.635806, radius_miles=50)\n",
    "print(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
